# YAML anchor for common Weaviate configuration
x-weaviate-common: &weaviate-common
  image: cr.weaviate.io/semitechnologies/weaviate:1.32.2
  restart: on-failure:0
  command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
  networks:
    - weaviate_net
  healthcheck:
    test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s
  environment: &weaviate-env
    QUERY_DEFAULTS_LIMIT: 25
    AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
    PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
    ENABLE_API_BASED_MODULES: 'true'
    ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
    CLUSTER_GOSSIP_BIND_PORT: '7946'
    CLUSTER_DATA_BIND_PORT: '7947'
    CLUSTER_JOIN: 'node1:7946,node2:7946,node3:7946'

services:
  weaviate-node1:
    <<: *weaviate-common
    container_name: weaviate-node1
    ports:
      - "8080:8080"
      - "50051:50051"
    volumes:
      - weaviate_node1_data:/var/lib/weaviate
    environment:
      <<: *weaviate-env
      CLUSTER_HOSTNAME: 'node1'

  weaviate-node2:
    <<: *weaviate-common
    container_name: weaviate-node2
    ports:
      - "8081:8080"
      - "50052:50051"
    volumes:
      - weaviate_node2_data:/var/lib/weaviate
    environment:
      <<: *weaviate-env
      CLUSTER_HOSTNAME: 'node2'
    depends_on:
      weaviate-node1:
        condition: service_healthy

  weaviate-node3:
    <<: *weaviate-common
    container_name: weaviate-node3
    ports:
      - "8082:8080"
      - "50053:50051"
    volumes:
      - weaviate_node3_data:/var/lib/weaviate
    environment:
      <<: *weaviate-env
      CLUSTER_HOSTNAME: 'node3'
    depends_on:
      weaviate-node1:
        condition: service_healthy
      weaviate-node2:
        condition: service_healthy

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-cluster
    ports:
      - "11435:11434"
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_MODELS: /opt/models
    volumes:
      - ollama_data:/root/.ollama
      - ./models:/opt/models:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - weaviate_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  ollama-init:
    image: ollama/ollama:latest
    container_name: ollama-init-cluster
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ollama_data:/root/.ollama
    environment:
      OLLAMA_HOST: ollama:11434
    entrypoint: |
      sh -c "
        echo 'Waiting for Ollama to be ready...'
        sleep 10
        echo 'Pulling nomic-embed-text model...'
        ollama pull nomic-embed-text
        echo 'Pulling llama3.2 model...'
        ollama pull llama3.2
        echo 'Models pulled successfully!'
      "
    restart: "no"
    networks:
      - weaviate_net

networks:
  weaviate_net:
    driver: bridge
    name: weaviate_cluster_network

volumes:
  weaviate_node1_data:
    driver: local
    name: weaviate_node1_data
  weaviate_node2_data:
    driver: local
    name: weaviate_node2_data
  weaviate_node3_data:
    driver: local
    name: weaviate_node3_data
  ollama_data:
    driver: local
    name: ollama_cluster_data
